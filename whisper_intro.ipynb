{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install requirements\n",
    "#choco install ffmpeg\n",
    "#pip install git+https://github.com/openai/whisper.git  for installing requirements\n",
    "#pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git for updating versions\n",
    "#pip install setuptools-rust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Available models and languages\n",
    "There are five model sizes, four with English-only versions, offering speed and accuracy tradeoffs. Below are the names of the available models and their approximate memory requirements and relative speed.\n",
    "\n",
    "Size\tParameters\tEnglish-only model\tMultilingual model\tRequired VRAM\tRelative speed\n",
    "tiny\t39 M\t        tiny.en\t            tiny\t        ~1 GB\t            ~32x\n",
    "base\t74 M\t        base.en\t            base\t        ~1 GB\t            ~16x\n",
    "small\t244 M\t        small.en\t        small\t        ~2 GB\t            ~6x\n",
    "medium\t769 M\t        medium.en\t        medium\t        ~5 GB\t            ~2x\n",
    "large\t1550 M\t        N/A         \t    large           ~10 GB\t            1x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omkar\\Documents\\GITHUB\\Whisper\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "file1='audio/sample_1.mp3'\n",
    "file2='audio/sample_2.mp3'\n",
    "file3='audio/sample_3.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omkar\\Documents\\GITHUB\\Whisper\\.venv\\lib\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.278022050857544\n",
      " How to use your first lesson. You should already have my lessons now, so I want to tell you how to use them. I'm very excited because soon you will speak English easily and fast. English words will come out of your mouth automatically. You'll feel relaxed and confident when you speak English and you'll feel happy when you learn with my lessons. No more sad boring lessons. So how do you use my lessons? Here are some suggestions. Start with the first lesson set named a day for the dead. Listen to all lessons in the set every day for one week. Learn deeply. Learn to the mini-story lesson two times a day or more. Answer the mini-story questions loudly. Do not think about grammar. Do not try to memorize. Just relax. Listen. Respond. Everything will happen automatically. Most importantly, relax and smile as you listen to the lessons. If you don't want to speak yet, it's okay. Effortless English is a listen-first system. Listening is most important. It's okay to just listen. You will improve quickly and automatically if you listen every day. That is the key. Listen to the lessons one hour or more every day. That is all you need to do. Do that and I guarantee your success. Good luck and enjoy the lessons. PS, if you don't have my lessons yet, get them now and start the first lesson set today. Start immediately.\n"
     ]
    }
   ],
   "source": [
    "start1=time.time()\n",
    "result1 = model.transcribe(file1)\n",
    "end1=time.time()\n",
    "print(end1-start1)\n",
    "print(result1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omkar\\Documents\\GITHUB\\Whisper\\.venv\\lib\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.069183588027954\n",
      " Fun in Osaka. The Osaka demonstration was great fun. I particularly enjoyed meeting some of our effortless English members in Japan. My only regret is that I didn't have time to talk to everyone longer. Next time we'll schedule more time to just sit and chat. Since the Osaka demonstration went well we'll be doing more workshops and seminars in the future. My plan is to develop two kinds of seminars, one for English teachers and one for English learners. There's a huge need for teacher training. As most English teachers either have no training at all or they are trained in grammar analysis practice methods. In other words they are only trained to use textbooks. Likewise I believe there is a need for student training. Most students don't know about the research. They don't know there are other ways to learn English. They only know what they have experienced in school, usually boring grammar-based textbook teaching. My goal for student seminars is to teach students a new way to learn independently. The Osaka seminar was my first one. It went well but I felt it was a big rough and needs improvement. When I get back to San Francisco I will start doing regular seminars in the city. In this way I can practice and improve both versions of the seminar. Once I'm satisfied with the quality we will go on tour and do seminars in different cities around the world.\n"
     ]
    }
   ],
   "source": [
    "start2=time.time()\n",
    "result2 = model.transcribe(file2)\n",
    "end2=time.time()\n",
    "print(end2-start2)\n",
    "print(result2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omkar\\Documents\\GITHUB\\Whisper\\.venv\\lib\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.89263200759888\n",
      " Learn English super fast. Learn English by focusing on content. Not grammar. What do I mean by content? I mean learn English by focusing on meaningful communication and meaningful information. Most schools and most students focus on the mechanics of the language. They study verb conjugations. They study the rules of prepositions. They analyze the language as if it was a dead thing. All of these traditional methods are analytical. But English is not a dead thing to analyze. It is a living language. It is a means of communication. Your brain is naturally fantastic at learning languages. Your brain is created to learn languages. But you must learn in ways that are friendly to your brain. If you bore your brain with rules, you will learn slowly. If you try to analyze the language, you will learn slowly. If you try to memorize vocabulary, you will learn slowly. If you study textbooks and take tests, you will learn slowly. Your brain is a super fast English learning machine. Use it correctly and you will learn super fast. Here's how to make your brain. Happy? And how to make your brain learn English super fast. Learn with stories. Our brains love stories. It's the oldest, most natural form of communication. Focus on meaning, not form. In other words, don't worry about grammar rules. Focus instead on meaning and being understood. Listen to the music of English carefully. To improve pronunciation, listen very carefully to the intonation of English speakers. And you are listening to music. Choose content you love. Only listen to and read English content that is interesting, meaningful or funny to you. If you don't enjoy it, find something else. Read easy novels, not textbooks. Again, the brain loves stories and hates boring drills. In your textbooks, read easy, fun, interesting English novels instead. Read a lot of them. Make friends. Join a community. English is for communication. So communicate with other English speakers. Forget about mistakes. Forget about grammar. Just relax and communicate. By smiling, having fun and focusing on meaningful content, you will make your brain happy and a happy brain learns very fast. Use these brain-friendly strategies to increase your English speaking and improve two to four times faster. Enjoy and speak English. Excellent.\n"
     ]
    }
   ],
   "source": [
    "start3=time.time()\n",
    "result3 = model.transcribe(file3)\n",
    "end3=time.time()\n",
    "print(end3-start3)\n",
    "print(result3['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage of whisper.detect_language() and whisper.decode() which provide lower-level access to the model.\\\n",
    "Language Detection and Transciption (30 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "Hey, I was doing just fine before I met you I drank too much and that's an issue, but I'm okay Hey, you tell your friends it was nice to meet them\n"
     ]
    }
   ],
   "source": [
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"audio/closer.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions(fp16 = False)\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whisper Transciption on a song - Closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omkar\\Documents\\GITHUB\\Whisper\\.venv\\lib\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.9007625579834\n",
      " Hey, I was doing just fine before I met you I drank too much and that's an issue, but I'm okay Hey, you tell your friends it was nice to meet them But I'll never see them again I know it breaks your heart, move to the city and I broke down Daring For years no boss, now you're looking pretty and I'll tell my friend No, I can't stop No, I can't stop So baby pull me closer in the back seat of your rover That I know you can't afford by tattoo on your shoulder Pull the sheets right off the corner of the mattress that you saw From your roommate back in board that we ain't never getting older Hey, hey, never getting older Hey, hey, never getting older Hey, hey, never getting older Look how good is the day I met you, I forget just why I left you I was insane Say, I played out drunk when I ate you to song Now we beat the death into song, okay I know it breaks your heart, move to the city and I broke down Daring For years no boss, now you're looking pretty and I'll tell my friend No, I can't stop No, I can't stop So baby pull me closer in the back seat of your rover That I know you can't afford by tattoo on your shoulder Pull the sheets right off the corner of the mattress that you saw From your roommate back in board that we ain't never getting older Hey, hey, never getting older Hey, hey, never getting older Hey, hey, never getting older So baby pull me closer in the back seat of your rover That I know you can't afford by tattoo on your shoulder Pull the sheets right off the corner of the mattress that you saw From your roommate back in board that we ain't never getting older Hey, hey, never getting older Hey, hey, never getting older Hey, hey, never getting older Hey, hey, never getting older Hey, hey, never getting older Hey, hey, never getting older Hey, hey, never getting older\n"
     ]
    }
   ],
   "source": [
    "start4=time.time()\n",
    "result4 = model.transcribe('audio/closer.mp3')\n",
    "end4=time.time()\n",
    "print(end4-start4)\n",
    "test=result4['text']\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "check=\"Hey, I was doing just fine before I met you I drink too much and that's an issue, but I'm okay Hey, you tell your friends it was nice to meet them But I hope I never see them again I know it breaks your heart Moved to the city in a broke-down car, and Four years, no calls Now you're looking pretty in a hotel bar And I, I, I, I, I can't stop No, I, I, I, I, I can't stop So, baby, pull me closer In the back seat of your Rover That I know you can't afford Bite that tattoo on your shoulder Pull the sheets right off the corner Of that mattress that you stole From your roommate back in Boulder We ain't ever getting older We ain't ever getting older We ain't ever getting older You look as good as the day I met you I forget just why I left you, I was insane Stay and play that Blink-182 song That we beat to death in Tucson, okay I know it breaks your heart Moved to the city in a broke-down car, and Four years, no call Now I'm looking pretty in a hotel bar And I, I, I, I, I can't stop No, I, I, I, I, I can't stop So, baby, pull me closer In the back seat of your Rover That I know you can't afford Bite that tattoo on your shoulder Pull the sheets right off the corner Of that mattress that you stole From your roommate back in Boulder We ain't ever getting older No, we ain't ever getting older We ain't ever getting older No, we ain't ever getting older We ain't ever getting older We ain't ever getting older We ain't ever getting older No, we ain't ever getting older We ain't ever getting older\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compression Similarity – leverages the pattern recognition of compression algorithms\\\n",
    "Euclidian Similarity – Treats text like points in multi-dimensional space and calculates their closeness\\\n",
    "Jaccard Similarity – Texts are more similar the more their words overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity: 0.45414847161572053\n",
      "Euclidian Similarity: 0.9330693970605337\n",
      "Compression Similarity: 0.5773874862788144\n"
     ]
    }
   ],
   "source": [
    "from simphile import jaccard_similarity, euclidian_similarity, compression_similarity\n",
    "\n",
    "print(f\"Jaccard Similarity: {jaccard_similarity(test,check)}\")\n",
    "print(f\"Euclidian Similarity: {euclidian_similarity(test,check)}\")\n",
    "print(f\"Compression Similarity: {compression_similarity(test,check)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!python -m spacy download en_core_web_sm\\\n",
    "The api 'similarity'` can be used to find the cosine similarity between the document vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import spacy\\nnlp = spacy.load('en_core_web_sm')\\ns1=nlp(test)\\ns1=nlp(check)\\nprint (s1.similarity(s2))\\n\\nAdd https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz to your requirements.txt file.\\n\\nNext, install using pip3 install --trusted-host files.pythonhosted.org --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host github.com -r requirements.txt\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "s1=nlp(test)\n",
    "s1=nlp(check)\n",
    "print (s1.similarity(s2))\n",
    "\n",
    "Add https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz to your requirements.txt file.\n",
    "\n",
    "Next, install using pip3 install --trusted-host files.pythonhosted.org --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host github.com -r requirements.txt\n",
    "'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command-Line usage\n",
    "\n",
    "<whisper audio.flac audio.mp3 audio.wav --model medium>\n",
    "\n",
    "The default setting (which selects the small model) works well for transcribing English.\\\n",
    " To transcribe an audio file containing non-English speech, you can specify the language using the --language option:\\\n",
    "<whisper japanese.wav --language Japanese>\n",
    "\n",
    "Adding --task translate will translate the speech into English:\\\n",
    "<whisper japanese.wav --language Japanese --task translate>\n",
    "\n",
    "Run the following to view all available options:\\\n",
    "<whisper --help>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
